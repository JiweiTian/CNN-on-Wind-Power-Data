{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values in training output: (350, 2)\n",
      "Number of values in validation output: (350, 2)\n"
     ]
    }
   ],
   "source": [
    "#Training data\n",
    "df1=pd.read_csv(\"wind_power_flow_data1.csv\")\n",
    "df2=pd.read_csv(\"power_flow_conv1.csv\")\n",
    "\n",
    "#print(df2)\n",
    "#print(df2)\n",
    "\n",
    "col1 = df1['MWh']\n",
    "col21 = df2[['Average','Variability']]\n",
    "\n",
    "\n",
    "\n",
    "#Validation data\n",
    "df3=pd.read_csv(\"wind_power_flow_data2.csv\")\n",
    "df4=pd.read_csv(\"power_flow_conv2.csv\")\n",
    "\n",
    "col3= df3['MWh']\n",
    "col41 = df4[['Average','Variability']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training data\n",
    "wind_power1 = col1.as_matrix()\n",
    "classify_output1 = col21.as_matrix()\n",
    "\n",
    "#converting to float32\n",
    "wind_power1.astype(float, copy=False)\n",
    "classify_output1.astype(float, copy=False)\n",
    "\n",
    "#Validation data\n",
    "wind_power2 = col3.as_matrix()\n",
    "classify_output2 = col41.as_matrix()\n",
    "\n",
    "#converting to float32\n",
    "wind_power2.astype(float, copy=False)\n",
    "classify_output2.astype(float, copy=False);\n",
    "\n",
    "\n",
    "#print(\"Number of values:\",np.count_nonzero(average_power1))\n",
    "print(\"Number of values in training output:\",classify_output1.shape)\n",
    "print(\"Number of values in validation output:\",classify_output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.391694]\n",
      "   [ 0.388492]\n",
      "   [ 0.386615]\n",
      "   ..., \n",
      "   [ 0.283319]\n",
      "   [ 0.240907]\n",
      "   [ 0.22122 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.226892]\n",
      "   [ 0.237066]\n",
      "   [ 0.261512]\n",
      "   ..., \n",
      "   [ 0.329363]\n",
      "   [ 0.34579 ]\n",
      "   [ 0.383075]]]\n",
      "\n",
      "\n",
      " [[[ 0.411239]\n",
      "   [ 0.459406]\n",
      "   [ 0.476016]\n",
      "   ..., \n",
      "   [ 0.948027]\n",
      "   [ 0.943393]\n",
      "   [ 0.963431]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.655609]\n",
      "   [ 0.634282]\n",
      "   [ 0.615162]\n",
      "   ..., \n",
      "   [ 0.370805]\n",
      "   [ 0.380299]\n",
      "   [ 0.383783]]]\n",
      "\n",
      "\n",
      " [[[ 0.378272]\n",
      "   [ 0.393201]\n",
      "   [ 0.391862]\n",
      "   ..., \n",
      "   [ 0.622414]\n",
      "   [ 0.643337]\n",
      "   [ 0.666998]]]\n",
      "\n",
      "\n",
      " [[[ 0.684243]\n",
      "   [ 0.690735]\n",
      "   [ 0.69413 ]\n",
      "   ..., \n",
      "   [ 0.43058 ]\n",
      "   [ 0.412425]\n",
      "   [ 0.395917]]]]\n",
      "[[ 0.32123958  0.14991743]\n",
      " [ 0.27448967  0.1749647 ]\n",
      " [ 0.77340729  0.53143856]\n",
      " [ 0.87074179  0.22627937]\n",
      " [ 0.81383646  0.38703368]\n",
      " [ 0.71497221  0.29172574]\n",
      " [ 0.20066887  0.28838797]\n",
      " [ 0.13548058  0.25268615]\n",
      " [ 0.51452454  0.27782923]\n",
      " [ 0.33550529  0.38662274]\n",
      " [ 0.52240825  0.26215155]\n",
      " [ 0.70465379  0.53572525]\n",
      " [ 0.60499817  0.53420977]\n",
      " [ 0.80302458  0.13978399]\n",
      " [ 0.59332771  0.68694378]\n",
      " [ 0.84492921  0.12390629]\n",
      " [ 0.58812858  0.66179859]\n",
      " [ 0.66685483  0.30977921]\n",
      " [ 0.82315829  0.28285395]\n",
      " [ 0.59263304  0.46708825]\n",
      " [ 0.40209421  0.52688026]\n",
      " [ 0.72659296  0.51988738]\n",
      " [ 0.588835    0.5365397 ]\n",
      " [ 0.85786763  0.13042054]\n",
      " [ 0.60137792  0.40114076]\n",
      " [ 0.66560933  0.47523246]\n",
      " [ 0.69085917  0.66480894]\n",
      " [ 0.51323279  0.25467449]\n",
      " [ 0.86677021  0.29452384]\n",
      " [ 0.81514804  0.34031871]\n",
      " [ 0.27084433  0.49276392]\n",
      " [ 0.40956821  0.48079428]\n",
      " [ 0.30834767  0.48534548]\n",
      " [ 0.29713446  0.548019  ]\n",
      " [ 0.44377954  0.61824394]\n",
      " [ 0.72581504  0.33208341]\n",
      " [ 0.62396242  0.29084646]\n",
      " [ 0.57638875  0.42648264]\n",
      " [ 0.17360279  0.4819035 ]\n",
      " [ 0.40322092  0.26240245]\n",
      " [ 0.20642708  0.5877989 ]\n",
      " [ 0.525695    0.72994465]\n",
      " [ 0.36414179  0.80123497]\n",
      " [ 0.67099958  0.38634609]\n",
      " [ 0.41128621  0.18852825]\n",
      " [ 0.48403513  0.29744373]\n",
      " [ 0.42418062  0.72221742]\n",
      " [ 0.68999342  0.24404636]\n",
      " [ 0.64237408  0.37197118]\n",
      " [ 0.52214467  0.61012495]\n",
      " [ 0.66860546  0.7140668 ]\n",
      " [ 0.77957121  0.32397968]\n",
      " [ 0.52307275  0.2701727 ]\n",
      " [ 0.597135    0.20035141]\n",
      " [ 0.33802558  0.49834905]\n",
      " [ 0.6471035   0.4830859 ]\n",
      " [ 0.80138962  0.51083512]\n",
      " [ 0.42107358  0.82193656]\n",
      " [ 0.57821287  0.39761446]\n",
      " [ 0.58259075  0.14475008]\n",
      " [ 0.40269963  0.32999858]\n",
      " [ 0.27555487  0.39554495]\n",
      " [ 0.23185933  0.29703347]\n",
      " [ 0.38424004  0.39457449]\n",
      " [ 0.67416246  0.21363276]\n",
      " [ 0.7109905   0.2373846 ]\n",
      " [ 0.31031371  0.59272836]\n",
      " [ 0.79027679  0.35111977]\n",
      " [ 0.47189146  0.73784938]\n",
      " [ 0.66859204  0.33580126]\n",
      " [ 0.45933942  0.70384207]\n",
      " [ 0.60460458  0.56610776]\n",
      " [ 0.79250033  0.57879725]\n",
      " [ 0.51194529  0.376152  ]\n",
      " [ 0.42813979  0.55197043]\n",
      " [ 0.64046958  0.19510642]\n",
      " [ 0.53602354  0.26449225]\n",
      " [ 0.59626987  0.49926577]\n",
      " [ 0.27631121  0.44255469]\n",
      " [ 0.71828963  0.34155471]\n",
      " [ 0.66739804  0.34499691]\n",
      " [ 0.12197208  0.29144636]\n",
      " [ 0.36249037  0.82942406]\n",
      " [ 0.50874633  0.81464151]\n",
      " [ 0.66761317  0.5122559 ]\n",
      " [ 0.72609825  0.31102044]\n",
      " [ 0.334547    0.93879039]\n",
      " [ 0.35150683  0.6344943 ]\n",
      " [ 0.60333871  0.26215119]\n",
      " [ 0.87004083  0.57985289]\n",
      " [ 0.60150958  0.89406947]\n",
      " [ 0.41874617  0.57613236]\n",
      " [ 0.50223538  0.39055563]\n",
      " [ 0.57945146  0.3927746 ]\n",
      " [ 0.47227846  0.29755251]\n",
      " [ 0.43273571  0.59533532]\n",
      " [ 0.32252162  0.64766181]\n",
      " [ 0.52528513  0.41177172]\n",
      " [ 0.67736783  0.58154157]\n",
      " [ 0.59911304  0.82914561]\n",
      " [ 0.31215675  0.40328809]\n",
      " [ 0.57905838  0.29870224]\n",
      " [ 0.75041908  0.42397779]\n",
      " [ 0.74566617  0.50672363]\n",
      " [ 0.33814554  0.43511515]\n",
      " [ 0.77860396  0.17810338]\n",
      " [ 0.39480383  0.8324568 ]\n",
      " [ 0.46554313  0.71435717]\n",
      " [ 0.69172004  0.36333866]\n",
      " [ 0.38482146  0.35521986]\n",
      " [ 0.54553988  0.51017904]\n",
      " [ 0.39862479  0.32960082]\n",
      " [ 0.72670304  0.14461721]\n",
      " [ 0.43790425  0.4231861 ]\n",
      " [ 0.27509587  0.37570157]\n",
      " [ 0.70396687  0.38995514]\n",
      " [ 0.87805492  0.16633822]\n",
      " [ 0.88093579  0.22342771]\n",
      " [ 0.70341271  0.10068268]\n",
      " [ 0.678697    0.13454469]\n",
      " [ 0.64615879  0.62218422]\n",
      " [ 0.5730415   0.65991208]\n",
      " [ 0.44472963  0.40855197]\n",
      " [ 0.43064567  0.16668177]\n",
      " [ 0.33774388  0.31735604]\n",
      " [ 0.71541088  0.2212722 ]\n",
      " [ 0.64712867  0.36270975]\n",
      " [ 0.59560058  0.45838672]\n",
      " [ 0.59638242  0.68940419]\n",
      " [ 0.42891154  0.37632408]\n",
      " [ 0.42414171  0.64130936]\n",
      " [ 0.62417296  0.46077959]\n",
      " [ 0.6597255   0.60565714]\n",
      " [ 0.25402771  0.44779762]\n",
      " [ 0.50527146  0.3671797 ]\n",
      " [ 0.11210342  0.2775905 ]\n",
      " [ 0.213141    0.2677262 ]\n",
      " [ 0.59971404  0.42830798]\n",
      " [ 0.67125579  0.54122158]\n",
      " [ 0.281283    0.32395799]\n",
      " [ 0.36240317  0.11229528]\n",
      " [ 0.19992529  0.32614418]\n",
      " [ 0.22455563  0.32119601]\n",
      " [ 0.35594525  0.25718057]\n",
      " [ 0.30192479  0.22045137]\n",
      " [ 0.2063985   0.19537734]\n",
      " [ 0.12212925  0.17516392]\n",
      " [ 0.20222333  0.30903812]\n",
      " [ 0.29281779  0.27491022]\n",
      " [ 0.27777875  0.3883258 ]\n",
      " [ 0.33181508  0.35426882]\n",
      " [ 0.42278613  0.28966546]\n",
      " [ 0.53502433  0.52648071]\n",
      " [ 0.24949396  0.29196339]\n",
      " [ 0.1606065   0.21674886]\n",
      " [ 0.25919408  0.24013847]\n",
      " [ 0.16155887  0.33517625]\n",
      " [ 0.35311483  0.1397043 ]\n",
      " [ 0.19941287  0.15603139]\n",
      " [ 0.17733379  0.25516543]\n",
      " [ 0.18467921  0.29433391]\n",
      " [ 0.22501963  0.30182628]\n",
      " [ 0.60009258  0.4489903 ]\n",
      " [ 0.35842012  0.42410245]\n",
      " [ 0.65712608  0.21877576]\n",
      " [ 0.57401071  0.4772234 ]\n",
      " [ 0.5499295   0.31791706]\n",
      " [ 0.45755717  0.1603011 ]\n",
      " [ 0.50793483  0.27298266]\n",
      " [ 0.38104121  0.49048291]\n",
      " [ 0.19023746  0.24708627]\n",
      " [ 0.17832983  0.37414297]\n",
      " [ 0.16910725  0.19900733]\n",
      " [ 0.11323958  0.13466954]\n",
      " [ 0.10798525  0.11631946]\n",
      " [ 0.07199217  0.19372405]\n",
      " [ 0.28216229  0.21334615]\n",
      " [ 0.47378092  0.27635816]\n",
      " [ 0.60635208  0.33394545]\n",
      " [ 0.51484521  0.26194945]\n",
      " [ 0.44037042  0.25616442]\n",
      " [ 0.69432142  0.34861852]\n",
      " [ 0.32059025  0.48718106]\n",
      " [ 0.06820237  0.13428799]\n",
      " [ 0.39543825  0.3261369 ]\n",
      " [ 0.40268704  0.30312154]\n",
      " [ 0.39553396  0.28300842]\n",
      " [ 0.32813267  0.44010778]\n",
      " [ 0.57528267  0.50724001]\n",
      " [ 0.104134    0.29002063]\n",
      " [ 0.37274821  0.4662816 ]\n",
      " [ 0.351827    0.63220754]\n",
      " [ 0.17521933  0.17471133]\n",
      " [ 0.28867154  0.32637518]\n",
      " [ 0.49265725  0.672965  ]\n",
      " [ 0.28366775  0.38537634]\n",
      " [ 0.03184463  0.07867052]\n",
      " [ 0.11394063  0.30791818]\n",
      " [ 0.38781225  0.33696335]\n",
      " [ 0.35202171  0.29074903]\n",
      " [ 0.46855383  0.22801417]\n",
      " [ 0.4061705   0.35604439]\n",
      " [ 0.39033025  0.2928678 ]\n",
      " [ 0.22282313  0.42648984]\n",
      " [ 0.26830971  0.32254044]\n",
      " [ 0.36905021  0.71191489]\n",
      " [ 0.23039704  0.23184039]\n",
      " [ 0.59818842  0.42049273]\n",
      " [ 0.20153996  0.37204324]\n",
      " [ 0.11366087  0.13430593]\n",
      " [ 0.05650179  0.1128159 ]\n",
      " [ 0.04425696  0.03838955]\n",
      " [ 0.02681983  0.0635765 ]\n",
      " [ 0.03524821  0.07532629]\n",
      " [ 0.06202554  0.13767827]\n",
      " [ 0.06977862  0.09632807]\n",
      " [ 0.0608195   0.12035698]\n",
      " [ 0.14716113  0.06309719]\n",
      " [ 0.20677079  0.10387306]\n",
      " [ 0.15158629  0.16113579]\n",
      " [ 0.18659475  0.21310158]\n",
      " [ 0.12162737  0.22802505]\n",
      " [ 0.41451108  0.3887618 ]\n",
      " [ 0.28274025  0.32131108]\n",
      " [ 0.16115421  0.15665138]\n",
      " [ 0.18943588  0.17473427]\n",
      " [ 0.23120475  0.19600973]\n",
      " [ 0.12688433  0.18019718]\n",
      " [ 0.105367    0.19690248]\n",
      " [ 0.19371537  0.25822226]\n",
      " [ 0.14298333  0.24545606]\n",
      " [ 0.19728783  0.16973773]\n",
      " [ 0.24076612  0.36624873]\n",
      " [ 0.07954462  0.16510463]\n",
      " [ 0.28813792  0.3693106 ]\n",
      " [ 0.34323108  0.30843677]\n",
      " [ 0.24159908  0.1618928 ]\n",
      " [ 0.13318275  0.340172  ]\n",
      " [ 0.09144167  0.17158791]\n",
      " [ 0.23023375  0.16032601]\n",
      " [ 0.28177983  0.19002739]\n",
      " [ 0.19955671  0.12696089]\n",
      " [ 0.39053908  0.25628885]\n",
      " [ 0.28614067  0.32736711]\n",
      " [ 0.16500942  0.23158288]\n",
      " [ 0.49970033  0.32482245]\n",
      " [ 0.58081621  0.30789537]\n",
      " [ 0.33091771  0.36753959]\n",
      " [ 0.17541483  0.19986388]\n",
      " [ 0.27961533  0.41946632]\n",
      " [ 0.50125296  0.24179808]\n",
      " [ 0.39758187  0.2399518 ]\n",
      " [ 0.66051008  0.51626618]\n",
      " [ 0.24121154  0.2857031 ]\n",
      " [ 0.11054246  0.08882054]\n",
      " [ 0.31657446  0.34956169]\n",
      " [ 0.23595563  0.41044399]\n",
      " [ 0.17645425  0.25093163]\n",
      " [ 0.14943762  0.21087374]\n",
      " [ 0.14256121  0.36549743]\n",
      " [ 0.32579721  0.56564905]\n",
      " [ 0.72461696  0.19516486]\n",
      " [ 0.55146804  0.3573546 ]\n",
      " [ 0.50409083  0.4546184 ]\n",
      " [ 0.1868775   0.40857459]\n",
      " [ 0.43850279  0.2748784 ]\n",
      " [ 0.38217796  0.26647831]\n",
      " [ 0.17257363  0.46688237]\n",
      " [ 0.34358667  0.35988297]\n",
      " [ 0.365088    0.28109359]\n",
      " [ 0.16115075  0.26711207]\n",
      " [ 0.2104745   0.35749962]\n",
      " [ 0.46401696  0.17452314]\n",
      " [ 0.31292125  0.41031863]\n",
      " [ 0.28723892  0.48030502]\n",
      " [ 0.87354771  0.36419822]\n",
      " [ 0.63244567  0.54759696]\n",
      " [ 0.39765633  0.43611365]\n",
      " [ 0.56510583  0.28550108]\n",
      " [ 0.63435167  0.46335829]\n",
      " [ 0.38627175  0.50587897]\n",
      " [ 0.20484021  0.25811122]\n",
      " [ 0.1455305   0.2223721 ]\n",
      " [ 0.29273592  0.6313698 ]\n",
      " [ 0.56303267  0.52204885]\n",
      " [ 0.45684308  0.94730542]\n",
      " [ 0.75620725  0.17999674]\n",
      " [ 0.36635908  0.45941701]\n",
      " [ 0.55216529  0.40047377]\n",
      " [ 0.78425625  0.36645374]\n",
      " [ 0.304941    0.39179614]\n",
      " [ 0.62750967  0.25649307]\n",
      " [ 0.33100158  0.39132714]\n",
      " [ 0.41969625  0.61646164]\n",
      " [ 0.63435229  0.25908549]\n",
      " [ 0.22957279  0.45951905]\n",
      " [ 0.35818179  0.41748216]\n",
      " [ 0.44345242  0.43466822]\n",
      " [ 0.685423    0.39639389]\n",
      " [ 0.50822137  0.49501175]\n",
      " [ 0.84253058  0.39959267]\n",
      " [ 0.315791    0.64765341]\n",
      " [ 0.43221125  0.77540559]\n",
      " [ 0.57979825  0.48171039]\n",
      " [ 0.70618967  0.29448287]\n",
      " [ 0.80036242  0.16035717]\n",
      " [ 0.67848942  0.25305051]\n",
      " [ 0.68246546  0.48954557]\n",
      " [ 0.5087255   0.43983835]\n",
      " [ 0.57068654  0.58877615]\n",
      " [ 0.69065696  0.5047514 ]\n",
      " [ 0.71135321  0.71592107]\n",
      " [ 0.36224775  0.45188159]\n",
      " [ 0.74869063  0.4818334 ]\n",
      " [ 0.886228    0.1590666 ]\n",
      " [ 0.68856208  0.18912012]\n",
      " [ 0.61263171  0.30562057]\n",
      " [ 0.13017333  0.37484422]\n",
      " [ 0.18166167  0.2097774 ]\n",
      " [ 0.60706121  0.37985138]\n",
      " [ 0.96378383  0.30203124]\n",
      " [ 0.64223479  0.38516212]\n",
      " [ 0.84264354  0.33573064]\n",
      " [ 0.48274479  0.64387111]\n",
      " [ 0.79213913  0.60633654]\n",
      " [ 0.79764738  0.47181418]\n",
      " [ 0.80459163  0.45374084]\n",
      " [ 1.00190329  0.11094159]\n",
      " [ 0.44381346  0.71595876]\n",
      " [ 0.49701625  0.16451265]\n",
      " [ 0.36527496  0.45368875]\n",
      " [ 0.51413575  0.54332312]\n",
      " [ 0.72428508  0.42182508]\n",
      " [ 0.92407033  0.18081387]\n",
      " [ 0.47773167  0.511488  ]\n",
      " [ 0.59048654  0.61178098]\n",
      " [ 0.5396185   0.81394949]\n",
      " [ 0.50002367  0.17173365]\n",
      " [ 0.18300525  0.44332157]\n",
      " [ 0.39168504  0.56490118]\n",
      " [ 0.79981121  0.22079815]\n",
      " [ 0.78487579  0.20392698]\n",
      " [ 0.29021638  0.42502307]\n",
      " [ 0.304673    0.18352054]\n",
      " [ 0.25219275  0.24113118]\n",
      " [ 0.46633054  0.48451065]\n",
      " [ 0.66027925  0.23258748]\n",
      " [ 0.50994808  0.30487403]\n",
      " [ 0.45039983  0.40477425]\n",
      " [ 0.60768575  0.34346764]]\n"
     ]
    }
   ],
   "source": [
    "#pmax = np.amax(wind_power)\n",
    "wind_power_max = 10000    #For normalization\n",
    "batch_size = 350           #Number of training samples\n",
    "output_size =2\n",
    "wind_power_reshape = np.resize(wind_power1/wind_power_max,(batch_size,1,24,1))\n",
    "classify_output1_reshape = np.resize(classify_output1,(batch_size,output_size))\n",
    "#Print reshaped input and output training data\n",
    "print(wind_power_reshape)\n",
    "print(classify_output1_reshape)\n",
    "#Validation data\n",
    "validate_batch = 350    #Number of validation samples\n",
    "wind_power_reshape_validate = np.resize(wind_power2/wind_power_max,(validate_batch,1,24,1))\n",
    "classify_output2_reshape_validate = np.resize(classify_output2,(validate_batch,output_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs after 1st convolution: 19\n",
      "Number of outputs after 2nd convolution: 14\n"
     ]
    }
   ],
   "source": [
    "#Power curve parameteres\n",
    "N =24 #Window\n",
    "Padding =0\n",
    "Stride =1\n",
    "Fn1 = 2 #Number of features\n",
    "Fn2 = 2 #Number of features\n",
    "Filter_size = 6\n",
    "Filter1_out = int((N -Filter_size + 2*Padding)/Stride  +1)\n",
    "Filter2_out = int((Filter1_out -Filter_size + 2*Padding)/Stride +1)\n",
    "\n",
    "O1 = 2 # Neurons in fully connected layer\n",
    "O2 = 2 # Number of outputs\n",
    "print(\"Number of outputs after 1st convolution:\",Filter1_out)\n",
    "print(\"Number of outputs after 2nd convolution:\",Filter2_out)\n",
    "training_iterations=100000\n",
    "display_iterations = 10000\n",
    "learning_rate1 = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input\n",
    "power = tf.placeholder(tf.float32,shape=(batch_size,1,24,1))#4x4 image (4D tensor = [1,1,6,1] = [batch size, width, height, number of channels]\n",
    "#Output\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "#Convolution layer weights\n",
    "power_filter1 = tf.Variable(tf.random_normal([1,Filter_size,1,Fn1])) #2x2 filter (4D tensor = [3,3,1,1] = [width, height, channels, number of filters]) \n",
    "power_filter2 = tf.Variable(tf.random_normal([1,Filter_size,Fn1,Fn2])) #2x2 filter (4D tensor = [3,3,1,1] = [width, height, channels, number of filters]) \n",
    "#Convolution layer biases\n",
    "b_conv1 = tf.Variable(tf.constant(0.1,shape=[Fn1]))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1,shape=[Fn2]))\n",
    "#Fully connected layer weights\n",
    "W_fc1 = tf.Variable(tf.random_normal([1*Filter2_out*Fn2,O1])) # Fully connected layer (2D tensor = [size of featur map*number of feature map,Number of neurons]) \n",
    "b_fc1 = tf.Variable(tf.constant(0.1,shape=[O1]))\n",
    "#Output layer weights\n",
    "W_fc2 = tf.Variable(tf.random_normal([O1,O2])) # Fully connected layer (2D tensor = [Number of input neurons,Number of output neurons]) \n",
    "b_fc2 = tf.Variable(tf.constant(0.1,shape=[O2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convolution layer\n",
    "convolve1 = tf.nn.conv2d(power, power_filter1, strides=[1, 1, 1, 1], padding='VALID')\n",
    "h_conv1 = tf.nn.relu(convolve1+b_conv1)\n",
    "convolve2 = tf.nn.conv2d(h_conv1, power_filter2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "h_conv2 = tf.nn.relu(convolve2+b_conv2)\n",
    "#Fully connected\n",
    "layer2_matrix = tf.reshape(h_conv2, [-1, 1*Filter2_out*Fn2])\n",
    "matmul_fc1=tf.matmul(layer2_matrix, W_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(matmul_fc1)\n",
    "#Output layer\n",
    "matmul_fc2=tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "output_layer = matmul_fc2  #Applying linear activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decreasing learning rate\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = learning_rate1\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,10000, 0.96, staircase=True)\n",
    "# Passing global_step to minimize() will increment it at each step.\n",
    "\n",
    "#Loss function\n",
    "mean_square = tf.reduce_sum(tf.square(y-output_layer))\n",
    "#train_step = tf.train.AdagradOptimizer(learning_rate).minimize(mean_square,global_step=global_step)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_square,global_step=global_step)\n",
    "\n",
    "#Operation to save variables\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at start: [139.45892]\n",
      "loss is: [137.0815] at itertion: 0\n",
      "learning rate is: [0.001] at itertion: 0\n",
      "loss is: [6.3683462] at itertion: 10000\n",
      "learning rate is: [0.00096000003] at itertion: 10000\n",
      "loss is: [6.3536558] at itertion: 20000\n",
      "learning rate is: [0.00092160003] at itertion: 20000\n",
      "loss is: [6.3522353] at itertion: 30000\n",
      "learning rate is: [0.00088473596] at itertion: 30000\n",
      "loss is: [6.351234] at itertion: 40000\n",
      "learning rate is: [0.00084934651] at itertion: 40000\n",
      "loss is: [6.3521814] at itertion: 50000\n",
      "learning rate is: [0.00081537262] at itertion: 50000\n",
      "loss is: [6.351593] at itertion: 60000\n",
      "learning rate is: [0.00078275776] at itertion: 60000\n",
      "loss is: [6.3506613] at itertion: 70000\n",
      "learning rate is: [0.0007514474] at itertion: 70000\n",
      "loss is: [6.3505363] at itertion: 80000\n",
      "learning rate is: [0.00072138949] at itertion: 80000\n",
      "loss is: [6.3502507] at itertion: 90000\n",
      "learning rate is: [0.00069253391] at itertion: 90000\n",
      "Model saved in file: /tmp/model.ckpt\n",
      "loss: [6.3502479]\n"
     ]
    }
   ],
   "source": [
    "#Initialization and session\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    power1 = np.reshape(wind_power_reshape[0:batch_size],(-1,1,24,1))\n",
    "    y1 = classify_output1_reshape[0:batch_size]\n",
    "    \n",
    "    print(\"loss at start:\",sess.run([mean_square],feed_dict={power:power1,y:y1}))\n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step],feed_dict={power:power1,y:y1})\n",
    "        if i%display_iterations ==0:\n",
    "            print(\"loss is:\",sess.run([mean_square],feed_dict={power:power1,y:y1}),\"at itertion:\",i)\n",
    "            print(\"learning rate is:\",sess.run([learning_rate]),\"at itertion:\",i)   \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"loss:\",sess.run([mean_square],feed_dict={power:power1,y:y1}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "loss: [6.3502479]\n",
      "loss is: [6.3500605] at itertion: 0\n",
      "loss is: [6.3501744] at itertion: 10000\n",
      "loss is: [6.3499079] at itertion: 20000\n",
      "loss is: [6.3496828] at itertion: 30000\n",
      "loss is: [6.3496141] at itertion: 40000\n",
      "loss is: [6.3493924] at itertion: 50000\n",
      "loss is: [6.349216] at itertion: 60000\n",
      "loss is: [6.3491611] at itertion: 70000\n",
      "loss is: [6.3487873] at itertion: 80000\n",
      "loss is: [6.3485479] at itertion: 90000\n",
      "Model saved in file: /tmp/model.ckpt\n",
      "loss: [6.3484631]\n"
     ]
    }
   ],
   "source": [
    "#Retrieve and continue session\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    power1 = np.reshape(wind_power_reshape[0:batch_size],(-1,1,24,1))\n",
    "    y1 = classify_output1_reshape[0:batch_size]\n",
    "    \n",
    "    \n",
    "    print(\"loss:\",sess.run([mean_square],feed_dict={power:power1,y:y1}))\n",
    "    \n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step],feed_dict={power:power1,y:y1})\n",
    "        if i%display_iterations ==0:\n",
    "             print(\"loss is:\",sess.run([mean_square],feed_dict={power:power1,y:y1}),\"at itertion:\",i)\n",
    "        \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"loss:\",sess.run([mean_square],feed_dict={power:power1,y:y1}))\n",
    "    yNN_trained =sess.run([output_layer],feed_dict={power:power1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "loss: [5.9791541]\n",
      "output: [array([[ 0.22763428,  0.27594358],\n",
      "       [ 0.33135596,  0.29770559],\n",
      "       [ 0.55898553,  0.34546492],\n",
      "       [ 0.64678097,  0.92180431],\n",
      "       [ 0.6472708 ,  0.36398822],\n",
      "       [ 0.50295687,  0.47633994],\n",
      "       [ 0.61811101,  0.70284843],\n",
      "       [ 0.66952097,  0.36865655],\n",
      "       [ 0.65705091,  0.6287927 ],\n",
      "       [ 0.73503751,  0.38240266],\n",
      "       [ 0.61153275,  0.35648996],\n",
      "       [ 0.66237962,  0.64689004],\n",
      "       [ 0.35999697,  0.30371481],\n",
      "       [ 0.18018019,  0.26598713],\n",
      "       [ 0.56266916,  0.34623778],\n",
      "       [ 0.67510432,  0.43280298],\n",
      "       [ 0.19836888,  0.28856856],\n",
      "       [ 0.73355186,  0.38209099],\n",
      "       [ 0.83121228,  0.40258127],\n",
      "       [ 0.51452488,  0.33613658],\n",
      "       [ 0.66130465,  0.39478433],\n",
      "       [ 0.14617798,  0.31659478],\n",
      "       [ 0.56352925,  0.34641826],\n",
      "       [ 0.46324807,  0.32537809],\n",
      "       [ 0.55481189,  0.34458923],\n",
      "       [ 0.4253048 ,  0.31741714],\n",
      "       [ 0.45046228,  0.81681901],\n",
      "       [ 0.19844061,  0.2698184 ],\n",
      "       [ 0.46729267,  0.32622668],\n",
      "       [ 0.75614256,  0.38683075],\n",
      "       [ 0.79659444,  0.39531803],\n",
      "       [ 0.38291889,  0.30852407],\n",
      "       [ 0.29471841,  0.29001859],\n",
      "       [ 0.37588438,  0.42620957],\n",
      "       [ 0.26835477,  0.29786083],\n",
      "       [ 0.44346544,  0.4383828 ],\n",
      "       [ 0.41418374,  0.3150838 ],\n",
      "       [ 0.35737318,  0.3031643 ],\n",
      "       [ 0.32349816,  0.29605693],\n",
      "       [ 0.5939222 ,  0.35279503],\n",
      "       [ 0.74283618,  0.38403893],\n",
      "       [ 0.81933451,  0.48685652],\n",
      "       [ 0.40263653,  0.31266105],\n",
      "       [ 0.36056161,  0.30383325],\n",
      "       [ 0.65726256,  0.36608458],\n",
      "       [ 0.35373667,  0.31447411],\n",
      "       [ 0.14844587,  0.2593289 ],\n",
      "       [ 0.647551  ,  0.36404699],\n",
      "       [ 0.8409245 ,  0.40461898],\n",
      "       [ 0.83295333,  0.40294656],\n",
      "       [ 0.31551182,  0.29438129],\n",
      "       [ 0.57253408,  0.34830755],\n",
      "       [ 0.32787186,  0.46538335],\n",
      "       [ 0.17375338,  0.26463872],\n",
      "       [ 0.11326213,  0.25194696],\n",
      "       [ 0.13976923,  0.25750846],\n",
      "       [ 0.59352231,  0.35271114],\n",
      "       [ 0.7280522 ,  0.3809371 ],\n",
      "       [ 0.44657066,  0.60391301],\n",
      "       [ 0.27983606,  0.28689611],\n",
      "       [ 0.14992407,  0.28414303],\n",
      "       [ 0.49313262,  0.33164823],\n",
      "       [ 0.48002851,  0.65648955],\n",
      "       [ 0.60599804,  0.35532868],\n",
      "       [ 0.25851154,  0.54377615],\n",
      "       [ 0.3947922 ,  0.31101525],\n",
      "       [ 0.47864509,  0.32860854],\n",
      "       [ 0.59275532,  0.35377377],\n",
      "       [ 0.74882197,  0.38529482],\n",
      "       [ 0.51713556,  0.38650388],\n",
      "       [ 0.78818476,  0.39355358],\n",
      "       [ 0.36550754,  0.4414314 ],\n",
      "       [ 0.29965398,  0.63799262],\n",
      "       [ 0.2572687 ,  0.28216121],\n",
      "       [ 0.31355885,  0.32973999],\n",
      "       [ 0.57898539,  0.34966111],\n",
      "       [ 0.74720842,  0.3849563 ],\n",
      "       [ 0.6505155 ,  0.36466897],\n",
      "       [ 0.66785347,  0.57108843],\n",
      "       [ 0.16237438,  0.27675384],\n",
      "       [ 0.06217759,  0.24122882],\n",
      "       [ 0.15049452,  0.25975874],\n",
      "       [ 0.59199566,  0.35239083],\n",
      "       [ 0.65590769,  0.39647636],\n",
      "       [ 0.17489764,  0.43880624],\n",
      "       [ 0.17270535,  0.26441884],\n",
      "       [ 0.1737895 ,  0.26464629],\n",
      "       [ 0.33911729,  0.29933399],\n",
      "       [ 0.42441422,  0.44646946],\n",
      "       [ 0.66559827,  0.36783352],\n",
      "       [ 0.4388186 ,  0.61746681],\n",
      "       [ 0.19117185,  0.26829332],\n",
      "       [ 0.52141821,  0.33758286],\n",
      "       [ 0.5249936 ,  0.61365217],\n",
      "       [ 0.56896007,  0.34755769],\n",
      "       [ 0.62912697,  0.36018142],\n",
      "       [ 0.28707871,  0.2884157 ],\n",
      "       [ 0.37126961,  0.30607992],\n",
      "       [ 0.6195116 ,  0.35816401],\n",
      "       [ 0.41430384,  0.31510901],\n",
      "       [ 0.35181162,  0.30199742],\n",
      "       [ 0.42619359,  0.31760362],\n",
      "       [ 0.29601732,  0.29029113],\n",
      "       [ 0.73066968,  0.38148624],\n",
      "       [ 0.62677854,  0.3596887 ],\n",
      "       [ 0.22519299,  0.27543136],\n",
      "       [ 0.51816827,  0.33690098],\n",
      "       [ 0.69060194,  0.3730796 ],\n",
      "       [ 0.80277628,  0.39661506],\n",
      "       [ 0.26438448,  0.28365418],\n",
      "       [ 0.62466985,  0.35924625],\n",
      "       [ 0.50261676,  0.3336381 ],\n",
      "       [ 0.55967969,  0.4996168 ],\n",
      "       [ 0.52858752,  0.33908707],\n",
      "       [ 0.44067255,  0.32064146],\n",
      "       [ 0.57563257,  0.5744583 ],\n",
      "       [ 0.28078857,  0.28709596],\n",
      "       [ 0.52855575,  0.33908039],\n",
      "       [ 0.32656795,  0.29670101],\n",
      "       [ 0.67504692,  0.59649003],\n",
      "       [ 0.71014601,  0.37718016],\n",
      "       [ 0.67435968,  0.36967176],\n",
      "       [ 0.63090277,  0.36055398],\n",
      "       [ 0.50691682,  0.45842591],\n",
      "       [ 0.17554495,  0.26501462],\n",
      "       [ 0.07598611,  0.24412601],\n",
      "       [ 0.08082729,  0.24514174],\n",
      "       [ 0.16521862,  0.26284802],\n",
      "       [ 0.42064294,  0.31643903],\n",
      "       [ 0.39811727,  0.58992177],\n",
      "       [ 0.67146355,  0.36906412],\n",
      "       [ 0.26088294,  0.37691605],\n",
      "       [ 0.54472828,  0.34247357],\n",
      "       [ 0.63662368,  0.3617543 ],\n",
      "       [ 0.33207679,  0.71290982],\n",
      "       [ 0.20547333,  0.27129394],\n",
      "       [ 0.33651644,  0.29878831],\n",
      "       [ 0.4067753 ,  0.31352943],\n",
      "       [ 0.47302657,  0.4156312 ],\n",
      "       [ 0.61765963,  0.35777542],\n",
      "       [ 0.38700625,  0.30938166],\n",
      "       [ 0.44072154,  0.32065177],\n",
      "       [ 0.45960531,  0.50363797],\n",
      "       [ 0.55152857,  0.34390035],\n",
      "       [ 0.59276396,  0.35255203],\n",
      "       [ 0.54211539,  0.34192538],\n",
      "       [ 0.34137788,  0.37006813],\n",
      "       [ 0.13732475,  0.27224725],\n",
      "       [ 0.44760385,  0.32209575],\n",
      "       [ 0.69206792,  0.37338716],\n",
      "       [ 0.7017917 ,  0.37542731],\n",
      "       [ 0.52168691,  0.33763924],\n",
      "       [ 0.24931234,  0.6400218 ],\n",
      "       [ 0.32847044,  0.29710016],\n",
      "       [ 0.38561022,  0.34948456],\n",
      "       [ 0.15754032,  0.26123703],\n",
      "       [ 0.14100111,  0.2577669 ],\n",
      "       [ 0.06631575,  0.24209705],\n",
      "       [ 0.43185842,  0.31879216],\n",
      "       [ 0.38644588,  0.42676213],\n",
      "       [ 0.08075576,  0.24512674],\n",
      "       [ 0.2263231 ,  0.27566847],\n",
      "       [ 0.46388665,  0.32551205],\n",
      "       [ 0.27910972,  0.59402454],\n",
      "       [ 0.51034546,  0.33525968],\n",
      "       [ 0.25489229,  0.3238259 ],\n",
      "       [ 0.20115435,  0.27038777],\n",
      "       [ 0.24104515,  0.27875733],\n",
      "       [ 0.12148986,  0.25367323],\n",
      "       [ 0.32075948,  0.29548231],\n",
      "       [ 0.62619311,  0.35956585],\n",
      "       [ 0.53486168,  0.40030742],\n",
      "       [ 0.33737281,  0.36747342],\n",
      "       [ 0.37461889,  0.39128911],\n",
      "       [ 0.28886545,  0.28879058],\n",
      "       [ 0.26430401,  0.28363729],\n",
      "       [ 0.26933092,  0.28469199],\n",
      "       [ 0.40754554,  0.31369102],\n",
      "       [ 0.69892222,  0.37482527],\n",
      "       [ 0.50664985,  0.33448428],\n",
      "       [ 0.24850684,  0.28032288],\n",
      "       [ 0.20919311,  0.2720744 ],\n",
      "       [ 0.10244723,  0.24967787],\n",
      "       [ 0.09144375,  0.2473692 ],\n",
      "       [ 0.39454684,  0.31096375],\n",
      "       [ 0.51381463,  0.33598754],\n",
      "       [ 0.45698935,  0.38885897],\n",
      "       [ 0.27214679,  0.41203094],\n",
      "       [ 0.11658563,  0.25264427],\n",
      "       [ 0.25434163,  0.28154707],\n",
      "       [ 0.24048826,  0.5277127 ],\n",
      "       [ 0.31764311,  0.29482847],\n",
      "       [ 0.58664745,  0.35126871],\n",
      "       [ 0.45269015,  0.44602913],\n",
      "       [ 0.27986437,  0.50142443],\n",
      "       [ 0.15754083,  0.26123714],\n",
      "       [ 0.20478228,  0.33507869],\n",
      "       [ 0.17228767,  0.26433119],\n",
      "       [ 0.50664651,  0.33448359],\n",
      "       [ 0.41072989,  0.62644106],\n",
      "       [ 0.07272821,  0.24344246],\n",
      "       [ 0.1298323 ,  0.25542358],\n",
      "       [ 0.30710217,  0.29261684],\n",
      "       [ 0.19768628,  0.35680336],\n",
      "       [ 0.05952385,  0.24067204],\n",
      "       [ 0.28373572,  0.2877143 ],\n",
      "       [ 0.46587294,  0.32592881],\n",
      "       [ 0.26084688,  0.28291196],\n",
      "       [ 0.16441664,  0.32768112],\n",
      "       [ 0.16385633,  0.26256222],\n",
      "       [ 0.04987437,  0.23864746],\n",
      "       [ 0.09137847,  0.24735551],\n",
      "       [ 0.14367664,  0.25832826],\n",
      "       [ 0.13778684,  0.25709251],\n",
      "       [ 0.09526717,  0.2481714 ],\n",
      "       [ 0.13083804,  0.25563458],\n",
      "       [ 0.14117277,  0.35637921],\n",
      "       [ 0.16973543,  0.2637957 ],\n",
      "       [ 0.13374573,  0.25624466],\n",
      "       [ 0.07843632,  0.2446401 ],\n",
      "       [ 0.14465213,  0.25853294],\n",
      "       [ 0.03857723,  0.23627719],\n",
      "       [ 0.09854526,  0.24885918],\n",
      "       [ 0.12587383,  0.25459304],\n",
      "       [ 0.14259571,  0.25810149],\n",
      "       [ 0.07649565,  0.24423292],\n",
      "       [ 0.09911095,  0.24897787],\n",
      "       [ 0.10783301,  0.25080785],\n",
      "       [ 0.21804509,  0.27393162],\n",
      "       [ 0.26791331,  0.28439456],\n",
      "       [ 0.34262633,  0.30007023],\n",
      "       [ 0.40114704,  0.31234854],\n",
      "       [ 0.36788115,  0.61524463],\n",
      "       [ 0.13734069,  0.2650151 ],\n",
      "       [ 0.27133211,  0.28511187],\n",
      "       [ 0.55169946,  0.3439362 ],\n",
      "       [ 0.59107959,  0.35219863],\n",
      "       [ 0.49305376,  0.40849829],\n",
      "       [ 0.36187997,  0.59428376],\n",
      "       [ 0.11984173,  0.25332743],\n",
      "       [ 0.18204552,  0.26637852],\n",
      "       [ 0.19311088,  0.26870015],\n",
      "       [ 0.11781583,  0.25290236],\n",
      "       [ 0.32253668,  0.29585519],\n",
      "       [ 0.14009118,  0.25757599],\n",
      "       [ 0.09823141,  0.24879333],\n",
      "       [ 0.10625347,  0.25047645],\n",
      "       [ 0.16263357,  0.26230565],\n",
      "       [ 0.38674152,  0.30932611],\n",
      "       [ 0.27113652,  0.46625847],\n",
      "       [ 0.21288145,  0.27284825],\n",
      "       [ 0.42946196,  0.31828937],\n",
      "       [ 0.2748324 ,  0.28584626],\n",
      "       [ 0.16045466,  0.26184851],\n",
      "       [ 0.32574466,  0.29652828],\n",
      "       [ 0.19289455,  0.26865476],\n",
      "       [ 0.46129957,  0.32496926],\n",
      "       [ 0.36627766,  0.43344852],\n",
      "       [ 0.25585848,  0.28186533],\n",
      "       [ 0.42380169,  0.31710178],\n",
      "       [ 0.50457168,  0.33404827],\n",
      "       [ 0.47207463,  0.34580532],\n",
      "       [ 0.41306421,  0.33741596],\n",
      "       [ 0.18043447,  0.2660405 ],\n",
      "       [ 0.52878869,  0.33912927],\n",
      "       [ 0.5743463 ,  0.3486878 ],\n",
      "       [ 0.21541542,  0.51354957],\n",
      "       [ 0.33832961,  0.29916874],\n",
      "       [ 0.59358376,  0.35272402],\n",
      "       [ 0.60281163,  0.35466015],\n",
      "       [ 0.50346547,  0.38801506],\n",
      "       [ 0.49091482,  0.3311829 ],\n",
      "       [ 0.57312936,  0.34843245],\n",
      "       [ 0.43191263,  0.74053919],\n",
      "       [ 0.38457599,  0.30887175],\n",
      "       [ 0.2391519 ,  0.2783601 ],\n",
      "       [ 0.48746791,  0.33045968],\n",
      "       [ 0.40249819,  0.31263205],\n",
      "       [ 0.35742992,  0.30317619],\n",
      "       [ 0.28085834,  0.30151749],\n",
      "       [ 0.61052179,  0.35627782],\n",
      "       [ 0.49642703,  0.33233941],\n",
      "       [ 0.51687998,  0.33663067],\n",
      "       [ 0.71841455,  0.37891501],\n",
      "       [ 0.55541825,  0.34471646],\n",
      "       [ 0.13993594,  0.25754344],\n",
      "       [ 0.62812907,  0.35997206],\n",
      "       [ 0.66311431,  0.36731237],\n",
      "       [ 0.28577909,  0.56888676],\n",
      "       [ 0.31926265,  0.29516825],\n",
      "       [ 0.3463079 ,  0.44642866],\n",
      "       [ 0.34666979,  0.30091861],\n",
      "       [ 0.53065002,  0.3395198 ],\n",
      "       [ 0.3290391 ,  0.29721949],\n",
      "       [ 0.18180963,  0.26632902],\n",
      "       [ 0.2273767 ,  0.27588952],\n",
      "       [ 0.32799888,  0.29700121],\n",
      "       [ 0.65916729,  0.36648422],\n",
      "       [ 0.60842437,  0.74678802],\n",
      "       [ 0.53768945,  0.34099674],\n",
      "       [ 0.53554404,  0.35158247],\n",
      "       [ 0.28446275,  0.34116822],\n",
      "       [ 0.20519891,  0.27123636],\n",
      "       [ 0.35034132,  0.30168894],\n",
      "       [ 0.5825578 ,  0.35041067],\n",
      "       [ 0.29299203,  0.47708917],\n",
      "       [ 0.74348778,  0.38417566],\n",
      "       [ 0.63663262,  0.78326094],\n",
      "       [ 0.46504927,  0.32575598],\n",
      "       [ 0.53595132,  0.66933709],\n",
      "       [ 0.39970684,  0.31204641],\n",
      "       [ 0.6452617 ,  0.36356667],\n",
      "       [ 0.79699695,  0.39540249],\n",
      "       [ 0.4214046 ,  0.31659883],\n",
      "       [ 0.69650161,  0.37431741],\n",
      "       [ 0.38757229,  0.30950043],\n",
      "       [ 0.874376  ,  0.41163751],\n",
      "       [ 0.56039399,  0.60811996],\n",
      "       [ 0.48304126,  0.32953092],\n",
      "       [ 0.73913312,  0.38326198],\n",
      "       [ 0.68635678,  0.3721889 ],\n",
      "       [ 0.54238665,  0.73863006],\n",
      "       [ 0.67282027,  0.36934876],\n",
      "       [ 0.61330748,  0.48806578],\n",
      "       [ 0.58627594,  0.35119078],\n",
      "       [ 0.49278465,  0.35237277],\n",
      "       [ 0.49663308,  0.67546785],\n",
      "       [ 0.74410671,  0.38430551],\n",
      "       [ 0.74166024,  0.59003365],\n",
      "       [ 0.71352005,  0.37788808],\n",
      "       [ 0.4825978 ,  0.32943788],\n",
      "       [ 0.38431829,  0.53713715],\n",
      "       [ 0.54555106,  0.34264621],\n",
      "       [ 0.44581655,  0.84256697],\n",
      "       [ 0.1273334 ,  0.25489926],\n",
      "       [ 0.40068185,  0.31225097],\n",
      "       [ 0.27839929,  0.28659466],\n",
      "       [ 0.50900537,  0.33497849],\n",
      "       [ 0.78107256,  0.49940655],\n",
      "       [ 0.3956953 ,  0.31120473],\n",
      "       [ 0.17452699,  0.41151887],\n",
      "       [ 0.1852268 ,  0.26704597],\n",
      "       [ 0.61418319,  0.35704604],\n",
      "       [ 0.54988438,  0.54423535],\n",
      "       [ 0.44808239,  0.32219613],\n",
      "       [ 0.43082383,  0.60330045],\n",
      "       [ 0.42539811,  0.31743672],\n",
      "       [ 0.34824887,  0.30124992],\n",
      "       [ 0.20670769,  0.27155292],\n",
      "       [ 0.36616582,  0.3050091 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    power2 = np.reshape(wind_power_reshape_validate[0:validate_batch],(-1,1,24,1))\n",
    "    y2 = classify_output2_reshape_validate[0:validate_batch]\n",
    "    print(\"loss:\",sess.run([mean_square],feed_dict={power:power2,y:y2}))\n",
    "    print(\"output:\",sess.run([output_layer],feed_dict={power:power2}))\n",
    "    yNN_validate = sess.run([output_layer],feed_dict={power:power2})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converting to numpy arrays\n",
    "yNN_validate=np.asarray(yNN_validate)\n",
    "yNN_trained=np.asarray(yNN_trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Saving CNN output\n",
    "np.savetxt(\"/tmp/NN_validate_output1.csv\", yNN_validate[:,:,0], delimiter=\",\")\n",
    "np.savetxt(\"/tmp/NN_validate_output2.csv\", yNN_validate[:,:,1], delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"/tmp/NN_trained_output1.csv\", yNN_trained[:,:,0], delimiter=\",\")\n",
    "np.savetxt(\"/tmp/NN_trained_output2.csv\", yNN_trained[:,:,1], delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Conv filter1: [array([[[[-0.26336747, -0.47294194]],\n",
      "\n",
      "        [[-0.51627028, -0.59489781]],\n",
      "\n",
      "        [[ 0.41553342, -2.24790382]],\n",
      "\n",
      "        [[-1.03019333, -1.95349717]],\n",
      "\n",
      "        [[ 0.37584552,  0.05892721]],\n",
      "\n",
      "        [[-0.22681765,  0.75300574]]]], dtype=float32)]\n",
      "Conv filter2: [array([[[[-0.67893624, -0.09012523],\n",
      "         [-1.50055158,  1.26097167]],\n",
      "\n",
      "        [[ 0.14149183, -0.30843493],\n",
      "         [ 1.33816707, -0.99697292]],\n",
      "\n",
      "        [[ 1.37863398,  1.60072029],\n",
      "         [-1.57425201,  1.50976384]],\n",
      "\n",
      "        [[-1.11969805, -0.54292911],\n",
      "         [ 1.2430557 ,  0.06524333]],\n",
      "\n",
      "        [[ 0.06871944,  0.65121651],\n",
      "         [-2.53878093,  1.06782794]],\n",
      "\n",
      "        [[-0.19633895,  0.39411393],\n",
      "         [ 0.49591494,  0.53815144]]]], dtype=float32)]\n",
      "Conv bias 1: [array([ 1.13493621,  0.03495971], dtype=float32)]\n",
      "Conv bias 2: [array([ 1.13493621,  0.03495971], dtype=float32)]\n",
      "Full connected layer 1 weights: [array([[ 0.95681661,  0.25760433],\n",
      "       [-0.29264909,  0.00298006],\n",
      "       [ 1.11845803,  0.35030979],\n",
      "       [ 0.27486694,  0.03546186],\n",
      "       [ 0.85201544,  0.47283918],\n",
      "       [ 0.46875313,  0.19342893],\n",
      "       [ 0.37617591,  0.32615438],\n",
      "       [ 0.14351083,  0.05724751],\n",
      "       [ 0.66392046,  1.02413368],\n",
      "       [-1.21356702, -0.43390319],\n",
      "       [ 1.0574131 ,  0.39207649],\n",
      "       [-0.14177188, -0.14721583],\n",
      "       [-0.33464944,  0.83850658],\n",
      "       [ 1.13292503,  0.4223052 ],\n",
      "       [ 0.47189552, -0.65715319],\n",
      "       [-0.02524716,  1.21457386],\n",
      "       [-2.16760397,  1.22411287],\n",
      "       [ 0.79333729, -1.3203553 ],\n",
      "       [-1.85762775, -0.02998351],\n",
      "       [-0.43388477, -0.01909653],\n",
      "       [-1.4409498 , -0.07655826],\n",
      "       [-0.17895913, -0.2198496 ],\n",
      "       [ 0.61119151,  0.09548795],\n",
      "       [-1.30665684,  0.5326407 ],\n",
      "       [ 0.66278654, -1.07979178],\n",
      "       [ 0.04717191,  0.79224175],\n",
      "       [-0.83268559,  1.04665935],\n",
      "       [ 0.73904794, -1.30989015]], dtype=float32)]\n",
      "Full connected layer 1 bias: [array([-0.16321053,  0.18605192], dtype=float32)]\n",
      "Full connected layer 2 weights: [array([[ 0.22818379,  1.46576619],\n",
      "       [ 0.39079988,  0.08199437]], dtype=float32)]\n",
      "Full connected layer 2 bias: [array([-0.00737701,  0.22663546], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk \n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    print(\"Conv filter1:\",sess.run([power_filter1]))\n",
    "    print(\"Conv filter2:\",sess.run([power_filter2]))\n",
    "    print(\"Conv bias 1:\",sess.run([b_conv1]))\n",
    "    print(\"Conv bias 2:\",sess.run([b_conv1]))\n",
    "    print(\"Full connected layer 1 weights:\",sess.run([W_fc1]))\n",
    "    print(\"Full connected layer 1 bias:\",sess.run([b_fc1]))\n",
    "    print(\"Full connected layer 2 weights:\",sess.run([W_fc2]))\n",
    "    print(\"Full connected layer 2 bias:\",sess.run([b_fc2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
